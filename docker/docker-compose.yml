version: '3.8'

services:
  # The Next.js Application
  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      target: deps
    container_name: percentage-tool-app
    restart: always
    ports:
      - "3000:3000"
    volumes:
      - ..:/app
      - /app/node_modules
      - /app/.next
    env_file:
      - ../.env
    environment:
      - HOSTNAME=0.0.0.0
      # Use the internal docker service name 'db' as the host
      - DATABASE_URL=postgres://pertool:pertool@db:5432/top_bottom_tool?schema=public
      # Pass through AI settings (assume user running LM Studio on host machine)
      # 'host.docker.internal' creates a bridge to the host machine's localhost
      - AI_HOST=http://host.docker.internal:1234/v1
      - LLM_MODEL=${LLM_MODEL:-meta-llama-3.1-8b-instruct}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-nomic-embed-text-v1.5}
    command: npm run dev
    depends_on:
      - db
    extra_hosts:
      - "host.docker.internal:host-gateway" # Helper to reach host's localhost

  # The Postgres Database
  db:
    image: postgres:15-alpine
    container_name: percentage-tool-db
    restart: always
    environment:
      POSTGRES_USER: pertool
      POSTGRES_PASSWORD: pertool
      POSTGRES_DB: top_bottom_tool
    ports:
      - "5433:5432" # Expose to host if you want to use Prisma Studio locally
    volumes:
      - db_data:/var/lib/postgresql/data

volumes:
  db_data:
