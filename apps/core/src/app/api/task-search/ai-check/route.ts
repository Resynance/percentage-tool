import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@repo/auth/server';
import { prisma } from '@repo/database';
import { generateCompletion } from '@repo/core/ai';

export const dynamic = 'force-dynamic';

const SYSTEM_PROMPT = `You are an expert at detecting whether task prompts were written by a human, generated by AI, or produced from a rigid template.

Definitions:
- AI_GENERATED: The prompt appears to have been written by an AI. Signs include: overly formal or flawless phrasing, unnaturally perfect grammar, generic or abstract scenarios, lack of personal context, formulaic sentence structures, and vocabulary patterns typical of LLMs.
- TEMPLATED: The prompt is clearly derived from a fill-in-the-blank template. Signs include: obvious variable substitution (names, dates, amounts dropped into fixed sentences), highly repetitive structure matching mass-produced tasks, and identical phrasing patterns with only specific details swapped.
- AUTHENTIC: The prompt appears genuinely written by a human. Signs include: natural variation in phrasing, minor imperfections, specific personal context, conversational tone, and idiosyncratic word choices.

Respond ONLY with valid JSON — no prose, no markdown, no code fences:
{
  "verdict": "AI_GENERATED" | "TEMPLATED" | "AUTHENTIC",
  "confidence": "HIGH" | "MEDIUM" | "LOW",
  "reasoning": "2–3 sentence explanation citing specific evidence from the text",
  "indicators": ["specific phrase or pattern that supports the verdict", "..."]
}`;

/**
 * POST /api/task-search/ai-check
 * Body: { content: string }
 * Runs an LLM check to assess whether the task looks AI-generated or templated.
 */
export async function POST(request: NextRequest) {
    const supabase = await createClient();
    const { data: { user }, error: authError } = await supabase.auth.getUser();

    if (authError || !user) {
        return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const profile = await prisma.profile.findUnique({
        where: { id: user.id },
        select: { role: true },
    });

    if (!profile || !['CORE', 'FLEET', 'MANAGER', 'ADMIN'].includes(profile.role)) {
        return NextResponse.json({ error: 'Forbidden' }, { status: 403 });
    }

    try {
        const { content } = await request.json();

        if (!content?.trim()) {
            return NextResponse.json({ error: 'content is required' }, { status: 400 });
        }

        const userPrompt = `Analyze this task prompt:\n\n${content.trim()}`;
        const raw = await generateCompletion(userPrompt, SYSTEM_PROMPT);

        // Extract JSON from the response (strip any accidental markdown fences)
        const jsonMatch = raw.match(/\{[\s\S]*\}/);
        if (!jsonMatch) {
            console.error('[AICheck] No JSON found in LLM response:', raw);
            return NextResponse.json({ error: 'AI returned an unexpected response format' }, { status: 502 });
        }

        const result = JSON.parse(jsonMatch[0]);

        const validVerdicts = ['AI_GENERATED', 'TEMPLATED', 'AUTHENTIC'];
        const validConfidences = ['HIGH', 'MEDIUM', 'LOW'];

        if (!validVerdicts.includes(result.verdict) || !validConfidences.includes(result.confidence)) {
            return NextResponse.json({ error: 'AI returned invalid verdict or confidence values' }, { status: 502 });
        }

        return NextResponse.json({
            verdict: result.verdict as 'AI_GENERATED' | 'TEMPLATED' | 'AUTHENTIC',
            confidence: result.confidence as 'HIGH' | 'MEDIUM' | 'LOW',
            reasoning: result.reasoning ?? '',
            indicators: Array.isArray(result.indicators) ? result.indicators : [],
        });
    } catch (error: any) {
        console.error('[AICheck] Error:', error);
        return NextResponse.json({ error: error.message || 'AI check failed' }, { status: 500 });
    }
}
